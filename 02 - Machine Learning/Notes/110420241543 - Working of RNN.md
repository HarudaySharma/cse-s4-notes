---
date: 2024-04-11T15:42
tags:
---
In any ***ordinary neural network*** we have ==different weights and biases across the hidden layers== **making them independent** and thereby **increasing the complexity** whereas in ***RNN*** the ==same weights and biases are provided== **to each of the hidden layers** thereby **reducing the complexity** by decreasing the input parameters and the output of the current hidden layer is given as the input of the next hidden layer.These hidden can be converted into a single recurrent layer